{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#use them on gooogle collbab  https://colab.research.google.com/drive/1E5Sqm1wKs61PvAEbuxk1KeRO6zBUbVQz\n",
    "\n",
    "\n",
    "link->\n",
    "#https://colab.research.google.com/drive/1E5Sqm1wKs61PvAEbuxk1KeRO6zBUbVQz?usp=sharing\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#data\n",
    "data={\n",
    "    'Feature1': [1.0,2.0,None,4.0,5.0],\n",
    "     'Feature2' : [2.0,None,4.0,5.0,None],\n",
    "      'Feature3': [None,4.0,5.0,3.0,3.5]\n",
    "}\n",
    "\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed=pd.DataFrame(imputer.fit_transform(df),columns=df.columns)\n",
    "print(df)\n",
    "print(\"after imputation\")\n",
    "print(df_imputed)\n",
    "\n",
    "\n",
    "\n",
    "#encoding categorial variables\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data={\n",
    "    'Color':['Red','Blue','Green','Blue','Red']\n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "print(df)\n",
    "print(\"After one hot coding\")\n",
    "\n",
    "encoder= OneHotEncoder(sparse=False)\n",
    "encoded_categories=encoder.fit_transform(df[['Color']])\n",
    "df_encoded=pd.DataFrame(encoded_categories,columns=encoder.get_feature_names_out(['Color']))\n",
    "df=pd.concat([df,df_encoded],axis=1).drop('Color',axis=1)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "#FEATURE SCALING\n",
    "#min-max\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Correcting the data dictionary\n",
    "data = {\n",
    "    'Feature1': [10, 20, 30, 40, 50],\n",
    "    'Feature2': [2.0, 4.0, 6.0, 8.0, 10.0]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "print(\"After Min-Max Scaling\")\n",
    "print(df_scaled)\n",
    "\n",
    "\n",
    "#4. Feature Creation\n",
    "\n",
    "#Feature creation is the process of creating new features from existing features.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "data = {\n",
    "    'Feature1': [10, 20, 30, 40, 50],\n",
    "    'Feature2': [2, 3, 4, 5, 6]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Feature creation\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(df)\n",
    "df_poly = pd.DataFrame(poly_features, columns=poly.get_feature_names_out(['Feature1', 'Feature2']))\n",
    "\n",
    "print(\"After Creating Polynomial Features:\\n\", df_poly)\n",
    "\n",
    "\n",
    "\n",
    "#FEATURE SELECTION\n",
    "#Feature selection is the process of selecting a subset(BEST) of features from a larger set of features.\n",
    "\n",
    "#1. VARIANCE THRESHOLDING\n",
    "#Variance thresholding is a feature selection method that removes features with low variance.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "data={\n",
    "    'Feature1': [1,1,1,1,1],\n",
    "    'Feature2': [2, 3, 4, 5, 6],\n",
    "    'Feature3': [10, 20, 30, 40, 50],\n",
    "    'Feature4': [1,1,1,1,1]\n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "selector=VarianceThreshold(threshold=0.1)\n",
    "df_variance_filtered =pd.DataFrame(selector.fit_transform(df), columns=df.columns[selector.get_support()])\n",
    "print(\"After Variance Thresholding:\\n\", df_variance_filtered)\n",
    "\n",
    "\n",
    "\n",
    "#2.CORRELATION MATRIX\n",
    "#Correlation matrix is a matrix that shows the correlation between features. Removing correlated data to reduce reduntancy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data\n",
    "data={\n",
    "    'Feature1': [1,2,3,4,5],\n",
    "    'Feature2': [1, 4, 9, 16, 25],\n",
    "    'Feature3': [1, 8, 27, 64, 125],\n",
    "    'Feature4': [1, 9,2,6,10]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "corr_matrix=df.corr().abs()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()\n",
    "#upper triangle remove kr rhe\n",
    "upper= corr_matrix.where(np.triu(np.ones(corr_matrix),k=1).astype(bool))\n",
    "\n",
    "\n",
    "to_drop= [column for column in upper.columns if any(upper[column]>0.9)]\n",
    "\n",
    "\n",
    "df_new= df.drop(to_drop,axis=1)\n",
    "print(\"After filtering\")\n",
    "print(df_new)\n",
    "\n",
    "#3 Domain knowledge\n",
    "#Domain knowledge is the knowledge of the domain of the problem. \n",
    "\n",
    "data={\n",
    "    'Age':[25,30,30,40,55],\n",
    "    'Salary':[50000,56000,60000,90000,555900],\n",
    "    'Height':[5.5,6.0,5.8,5.9,6.1],\n",
    "    'Weight':[60,70,65,75,80]\n",
    "\n",
    "}\n",
    "df =pd.DataFrame(data)\n",
    "\n",
    "selected_features_domain=df[['Age','Salary']]\n",
    "print(\"Selected Features on Domain Knowledge: \\n\", selected_features_domain)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
